Facebook on Tuesday teamed up with the London Police to help its artificial intelligence tools track live streams of terror attacks such as the New Zealand mosque massacre. A self-professed white supremacist used a head-mounted camera in March to broadcast live footage on Facebook of him attacking two mosques in the city of Christchurch. Facebook and platforms such as YouTube came under intense criticism for initially failing to detect the broadcast and then struggling to take down its uploads that proliferated online. The California-based social media behemoth on Tuesday said it was in the process of updating and refining its policies for dealing with extremism and online hate. “Some of these changes predate the tragic terrorist attack in Christ church, New Zealand, but that attack, and the global response to it in the form of the Christchurch Call to Action, has strongly influenced the recent updates to our policies and their enforcement.” London’s Metropolitan Police said the initiative will see it provide Facebook footage of training by its forearms command unit. The videos will be captured on body cameras provided by Facebook that London’s Firearms Command officers wear during exercises. This will help Facebook “capture the volume of images needed to train our machine learning tools,” the company said. “This will mean our AI tools will be able to more accurately and rapidly identify real-life first-person shooter incidents and remove them from our platform.” The London police said its footage will be combined with video Facebookis already using from law enforcement agencies in the United States. The Metropolitan Police said Facebook decided to ask London for help because it has created the world’s first counter-terror internet response team focused on online hate. Facebook said that it was also expanding to Australia and Indonesia a US programme in which users, who search for extremist content on the platform are directed to a special support group.